{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda9441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59106b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_root = './datasets/augmented'\n",
    "padding_root = './datasets/padding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e7e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FUNCTION TO EXTRACT EMOTION LABEL\n",
    "emotion = []\n",
    "file_path = []\n",
    "\n",
    "def get_emotion_path_list(root):\n",
    "    emotion_list = []\n",
    "    path_list = []\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if name.endswith(\".wav\"):\n",
    "                # print(path.split(\"/\")[2]) # label\n",
    "                emotion_list.append(path.split(\"/\")[3])\n",
    "                path_list.append(os.path.join(path, name))\n",
    "    return emotion_list, path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b780b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion, file_path = get_emotion_path_list(padding_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac989d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b931236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taunt</td>\n",
       "      <td>./datasets/padding/taunt/padding_re-threat-57.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taunt</td>\n",
       "      <td>./datasets/padding/taunt/padding_re-threat-43.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taunt</td>\n",
       "      <td>./datasets/padding/taunt/padding_re-threat-80.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taunt</td>\n",
       "      <td>./datasets/padding/taunt/padding_re-threat-81.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taunt</td>\n",
       "      <td>./datasets/padding/taunt/padding_re-threat-42.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               path\n",
       "0  taunt  ./datasets/padding/taunt/padding_re-threat-57.wav\n",
       "1  taunt  ./datasets/padding/taunt/padding_re-threat-43.wav\n",
       "2  taunt  ./datasets/padding/taunt/padding_re-threat-80.wav\n",
       "3  taunt  ./datasets/padding/taunt/padding_re-threat-81.wav\n",
       "4  taunt  ./datasets/padding/taunt/padding_re-threat-42.wav"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PUT EXTRACTED LABELS WITH FILEPATH INTO DATAFRAME\n",
    "padding_audio_df = pd.DataFrame(emotion)\n",
    "padding_audio_df.columns = ['labels']\n",
    "padding_audio_df = pd.concat([padding_audio_df, pd.DataFrame(file_path, columns = ['path'])], axis=1)\n",
    "print(len(padding_audio_df))\n",
    "padding_audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d590a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion, file_path = get_emotion_path_list(augmented_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT EXTRACTED LABELS WITH FILEPATH INTO DATAFRAME\n",
    "augmented_audio_df = pd.DataFrame(emotion)\n",
    "augmented_audio_df.columns = ['labels']\n",
    "augmented_audio_df = pd.concat([augmented_audio_df, pd.DataFrame(file_path, columns = ['path'])], axis=1)\n",
    "augmented_audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e165e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.concat([padding_audio_df, augmented_audio_df], axis=0, ignore_index=True )\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(audio_df[audio_df.labels == 'taunt']))\n",
    "print(len(audio_df[audio_df.labels == 'upset']))\n",
    "print(len(audio_df[audio_df.labels == 'angry']))\n",
    "print(len(audio_df[audio_df.labels == 'calm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df26b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSURE COLUMN VALUES ARE CORRECT\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "audio_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT DISTRIBUTION OF CLASSES\n",
    "audio_df.labels.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2fa5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6be1845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-387.3323, 41.278095, -26.217411, 23.478987, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-371.9092, 75.07741, -31.255543, 11.7239065, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-370.3928, 39.215595, -22.409412, 15.02184, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-447.38538, 29.748251, -6.235247, 5.735924, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-419.0164, 65.34434, -6.7146897, 9.1543865, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features\n",
       "0  [-387.3323, 41.278095, -26.217411, 23.478987, ...\n",
       "1  [-371.9092, 75.07741, -31.255543, 11.7239065, ...\n",
       "2  [-370.3928, 39.215595, -22.409412, 15.02184, -...\n",
       "3  [-447.38538, 29.748251, -6.235247, 5.735924, -...\n",
       "4  [-419.0164, 65.34434, -6.7146897, 9.1543865, -..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITERATE OVER ALL AUDIO FILES AND EXTRACT LOG MEL SPECTROGRAM MEAN VALUES INTO DF FOR MODELING \n",
    "df = pd.DataFrame(columns=['features'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index, path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast', duration=10.0, sr=None)\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # fmin 和 fmax 對應於人類語音的最小最大基本頻率\n",
    "    pitches, magnitudes = librosa.piptrack(X, sr=sample_rate, S=stft, fmin=70, fmax=400)\n",
    "    pitch = []\n",
    "    for i in range(magnitudes.shape[1]):\n",
    "        index = magnitudes[:, 1].argmax()\n",
    "        pitch.append(pitches[index, i])\n",
    "\n",
    "    pitch_tuning_offset = librosa.pitch_tuning(pitches)\n",
    "    pitchmean = np.mean(pitch)\n",
    "    pitchstd = np.std(pitch)\n",
    "    pitchmax = np.max(pitch)\n",
    "    pitchmin = np.min(pitch)\n",
    "\n",
    "    # 頻譜質心\n",
    "    cent = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "    cent = cent / np.sum(cent)\n",
    "    meancent = np.mean(cent)\n",
    "    stdcent = np.std(cent)\n",
    "    maxcent = np.max(cent)\n",
    "\n",
    "    # 譜平面\n",
    "    flatness = np.mean(librosa.feature.spectral_flatness(y=X))\n",
    "\n",
    "    # 使用系數為13的MFCC特徵\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
    "    mfccsstd = np.std(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
    "    mfccmax = np.max(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
    "\n",
    "    # 色譜圖\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "\n",
    "    # 梅爾頻率\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
    "\n",
    "    # ottava對比\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "\n",
    "    # 過零率\n",
    "    zerocr = np.mean(librosa.feature.zero_crossing_rate(X))\n",
    "\n",
    "    S, phase = librosa.magphase(stft)\n",
    "    meanMagnitude = np.mean(S)\n",
    "    stdMagnitude = np.std(S)\n",
    "    maxMagnitude = np.max(S)\n",
    "\n",
    "    # 均方根能量\n",
    "    rms = librosa.feature.rms(S=S)[0]\n",
    "    meanrms = np.mean(rms)\n",
    "    stdrms = np.std(rms)\n",
    "    maxrms = np.max(rms)\n",
    "\n",
    "    ext_features = np.array([\n",
    "        flatness, zerocr, meanMagnitude, maxMagnitude, meancent, stdcent,\n",
    "        maxcent, stdMagnitude, pitchmean, pitchmax, pitchstd,\n",
    "        pitch_tuning_offset, meanrms, maxrms, stdrms\n",
    "    ])\n",
    "\n",
    "    ext_features = np.concatenate((ext_features, mfccs, mfccsstd, mfccmax, chroma, mel, contrast))\n",
    "        \n",
    "    df.loc[counter] = [ext_features]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2c0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([audio_df, pd.DataFrame(df['features'].values.tolist())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a493f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa43b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP PATH COLUMN FOR MODELING\n",
    "df_combined.drop(columns='path', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c5bf4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taunt</td>\n",
       "      <td>-387.332306</td>\n",
       "      <td>41.278095</td>\n",
       "      <td>-26.217411</td>\n",
       "      <td>23.478987</td>\n",
       "      <td>-21.221752</td>\n",
       "      <td>-3.167870</td>\n",
       "      <td>-2.555068</td>\n",
       "      <td>-7.530316</td>\n",
       "      <td>-7.812870</td>\n",
       "      <td>...</td>\n",
       "      <td>136.050446</td>\n",
       "      <td>27.569355</td>\n",
       "      <td>59.000580</td>\n",
       "      <td>48.622795</td>\n",
       "      <td>31.801010</td>\n",
       "      <td>24.387249</td>\n",
       "      <td>21.796705</td>\n",
       "      <td>15.529959</td>\n",
       "      <td>28.728931</td>\n",
       "      <td>26.144257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taunt</td>\n",
       "      <td>-371.909210</td>\n",
       "      <td>75.077408</td>\n",
       "      <td>-31.255543</td>\n",
       "      <td>11.723907</td>\n",
       "      <td>1.083341</td>\n",
       "      <td>-5.691078</td>\n",
       "      <td>-6.333925</td>\n",
       "      <td>3.393700</td>\n",
       "      <td>-7.370813</td>\n",
       "      <td>...</td>\n",
       "      <td>86.733742</td>\n",
       "      <td>34.921051</td>\n",
       "      <td>19.416603</td>\n",
       "      <td>25.906837</td>\n",
       "      <td>47.580502</td>\n",
       "      <td>20.488594</td>\n",
       "      <td>25.857126</td>\n",
       "      <td>31.091980</td>\n",
       "      <td>11.447498</td>\n",
       "      <td>13.655737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taunt</td>\n",
       "      <td>-370.392792</td>\n",
       "      <td>39.215595</td>\n",
       "      <td>-22.409412</td>\n",
       "      <td>15.021840</td>\n",
       "      <td>-19.398071</td>\n",
       "      <td>-0.971972</td>\n",
       "      <td>-0.389927</td>\n",
       "      <td>-5.652776</td>\n",
       "      <td>-8.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>119.755768</td>\n",
       "      <td>19.233610</td>\n",
       "      <td>65.026779</td>\n",
       "      <td>33.770046</td>\n",
       "      <td>23.649931</td>\n",
       "      <td>7.127609</td>\n",
       "      <td>36.682632</td>\n",
       "      <td>13.555176</td>\n",
       "      <td>30.341942</td>\n",
       "      <td>22.073078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taunt</td>\n",
       "      <td>-447.385376</td>\n",
       "      <td>29.748251</td>\n",
       "      <td>-6.235247</td>\n",
       "      <td>5.735924</td>\n",
       "      <td>-7.789796</td>\n",
       "      <td>2.991443</td>\n",
       "      <td>-6.330763</td>\n",
       "      <td>-0.119231</td>\n",
       "      <td>-5.614090</td>\n",
       "      <td>...</td>\n",
       "      <td>89.400787</td>\n",
       "      <td>24.531925</td>\n",
       "      <td>46.112801</td>\n",
       "      <td>15.662816</td>\n",
       "      <td>31.338982</td>\n",
       "      <td>11.347013</td>\n",
       "      <td>18.708534</td>\n",
       "      <td>13.111612</td>\n",
       "      <td>19.380270</td>\n",
       "      <td>29.571518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taunt</td>\n",
       "      <td>-419.016388</td>\n",
       "      <td>65.344337</td>\n",
       "      <td>-6.714690</td>\n",
       "      <td>9.154387</td>\n",
       "      <td>-8.516296</td>\n",
       "      <td>2.051010</td>\n",
       "      <td>-5.422795</td>\n",
       "      <td>4.942542</td>\n",
       "      <td>-3.922849</td>\n",
       "      <td>...</td>\n",
       "      <td>103.666702</td>\n",
       "      <td>10.647741</td>\n",
       "      <td>48.276596</td>\n",
       "      <td>16.777142</td>\n",
       "      <td>35.848019</td>\n",
       "      <td>9.932405</td>\n",
       "      <td>26.478540</td>\n",
       "      <td>17.704189</td>\n",
       "      <td>8.592093</td>\n",
       "      <td>22.425457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels           0          1          2          3          4         5  \\\n",
       "0  taunt -387.332306  41.278095 -26.217411  23.478987 -21.221752 -3.167870   \n",
       "1  taunt -371.909210  75.077408 -31.255543  11.723907   1.083341 -5.691078   \n",
       "2  taunt -370.392792  39.215595 -22.409412  15.021840 -19.398071 -0.971972   \n",
       "3  taunt -447.385376  29.748251  -6.235247   5.735924  -7.789796  2.991443   \n",
       "4  taunt -419.016388  65.344337  -6.714690   9.154387  -8.516296  2.051010   \n",
       "\n",
       "          6         7         8  ...          29         30         31  \\\n",
       "0 -2.555068 -7.530316 -7.812870  ...  136.050446  27.569355  59.000580   \n",
       "1 -6.333925  3.393700 -7.370813  ...   86.733742  34.921051  19.416603   \n",
       "2 -0.389927 -5.652776 -8.247676  ...  119.755768  19.233610  65.026779   \n",
       "3 -6.330763 -0.119231 -5.614090  ...   89.400787  24.531925  46.112801   \n",
       "4 -5.422795  4.942542 -3.922849  ...  103.666702  10.647741  48.276596   \n",
       "\n",
       "          32         33         34         35         36         37         38  \n",
       "0  48.622795  31.801010  24.387249  21.796705  15.529959  28.728931  26.144257  \n",
       "1  25.906837  47.580502  20.488594  25.857126  31.091980  11.447498  13.655737  \n",
       "2  33.770046  23.649931   7.127609  36.682632  13.555176  30.341942  22.073078  \n",
       "3  15.662816  31.338982  11.347013  18.708534  13.111612  19.380270  29.571518  \n",
       "4  16.777142  35.848019   9.932405  26.478540  17.704189   8.592093  22.425457  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK TOP 5 ROWS\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbaadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('for_lstm_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d50dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_combined.iloc[:, 1:].values\n",
    "Y = df_combined['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80600988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7d49d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['taunt']\n",
      " ['taunt']\n",
      " ['taunt']\n",
      " ...\n",
      " ['upset']\n",
      " ['upset']\n",
      " ['upset']]\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "print(np.array(Y).reshape(-1, 1))\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d6e50ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-387.3323   ,   41.278095 ,  -26.217411 ,   23.478987 ,\n",
       "        -21.221752 ,   -3.1678698,   -2.5550678,   -7.5303164,\n",
       "         -7.81287  ,   -1.375793 ,   -5.238518 ,   -4.3855257,\n",
       "         -1.7967204,  151.23877  ,   47.150234 ,   56.979397 ,\n",
       "         33.466167 ,   33.72315  ,   20.807877 ,   18.469158 ,\n",
       "         17.305733 ,   13.989556 ,    9.296504 ,    8.787268 ,\n",
       "          8.41936  ,    8.934577 ,  -25.01341  ,  165.70148  ,\n",
       "         69.390305 ,  136.05045  ,   27.569355 ,   59.00058  ,\n",
       "         48.622795 ,   31.80101  ,   24.387249 ,   21.796705 ,\n",
       "         15.529959 ,   28.728931 ,   26.144257 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c791fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((786, 39), (786, 4), (263, 39), (263, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc51ce41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-524.29095   ,   52.08505   ,    4.8364167 ,   12.7117195 ,\n",
       "          1.6259842 ,   13.291577  ,    2.7669728 ,    5.052408  ,\n",
       "         -0.90490085,   -0.68331736,    1.7970308 ,    1.8669195 ,\n",
       "          1.4591393 ,  126.71241   ,   64.488976  ,   17.640116  ,\n",
       "         21.681257  ,   14.017623  ,   18.543316  ,   11.415767  ,\n",
       "          9.276158  ,    8.251394  ,    7.165609  ,    7.1093373 ,\n",
       "          6.762876  ,    6.9752545 , -214.26495   ,  217.60704   ,\n",
       "         76.92479   ,  118.00828   ,   48.57874   ,   77.765656  ,\n",
       "         28.894896  ,   50.303497  ,   19.493467  ,   17.693916  ,\n",
       "         26.904854  ,   22.867046  ,   43.541748  ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92547808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((786, 39), (786, 4), (263, 39), (263, 4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b53aeeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.89290524,  0.3572929 ,  1.280064  ,  0.11423127,  1.3901958 ,\n",
       "        1.7453734 ,  1.3705877 ,  1.2546271 ,  0.8713353 ,  0.3020591 ,\n",
       "        1.5129595 ,  1.6216    ,  0.72618717, -0.9500413 ,  0.6809286 ,\n",
       "       -1.2027407 , -0.44562182, -1.2228798 ,  1.2412442 , -0.76055324,\n",
       "       -0.53835773, -1.020421  , -0.6679094 , -0.57252115, -0.9182528 ,\n",
       "       -0.19809683, -1.325526  ,  0.89036185,  1.2346404 ,  0.48670873,\n",
       "        1.333638  ,  1.1848007 ,  0.32143828,  1.2232277 , -0.14829738,\n",
       "       -0.80525887,  0.72423744,  0.6890617 ,  1.3716886 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d65135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((786, 39, 1), (786, 4), (263, 39, 1), (263, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab49450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89290524],\n",
       "       [ 0.3572929 ],\n",
       "       [ 1.280064  ],\n",
       "       [ 0.11423127],\n",
       "       [ 1.3901958 ],\n",
       "       [ 1.7453734 ],\n",
       "       [ 1.3705877 ],\n",
       "       [ 1.2546271 ],\n",
       "       [ 0.8713353 ],\n",
       "       [ 0.3020591 ],\n",
       "       [ 1.5129595 ],\n",
       "       [ 1.6216    ],\n",
       "       [ 0.72618717],\n",
       "       [-0.9500413 ],\n",
       "       [ 0.6809286 ],\n",
       "       [-1.2027407 ],\n",
       "       [-0.44562182],\n",
       "       [-1.2228798 ],\n",
       "       [ 1.2412442 ],\n",
       "       [-0.76055324],\n",
       "       [-0.53835773],\n",
       "       [-1.020421  ],\n",
       "       [-0.6679094 ],\n",
       "       [-0.57252115],\n",
       "       [-0.9182528 ],\n",
       "       [-0.19809683],\n",
       "       [-1.325526  ],\n",
       "       [ 0.89036185],\n",
       "       [ 1.2346404 ],\n",
       "       [ 0.48670873],\n",
       "       [ 1.333638  ],\n",
       "       [ 1.1848007 ],\n",
       "       [ 0.32143828],\n",
       "       [ 1.2232277 ],\n",
       "       [-0.14829738],\n",
       "       [-0.80525887],\n",
       "       [ 0.72423744],\n",
       "       [ 0.6890617 ],\n",
       "       [ 1.3716886 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07d4fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e1c7ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 39, 64)            16896     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 29,444\n",
      "Trainable params: 29,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=64, dropout=0.05, recurrent_dropout=0.20, activation=\"tanh\", return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(units=32, dropout=0.05, recurrent_dropout=0.20, activation=\"tanh\", return_sequences=False))\n",
    "model.add(Dense(4, activation='softmax')) # A, B, C\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bbf6efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 04:10:18.339471: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - ETA: 0s - loss: 1.3574 - acc: 0.4237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 04:11:35.818864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 80s 6s/step - loss: 1.3574 - acc: 0.4237 - val_loss: 1.2941 - val_acc: 0.4639\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.35737, saving model to ./lstm_model.hdf5\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 78s 6s/step - loss: 1.2095 - acc: 0.4847 - val_loss: 1.1466 - val_acc: 0.4563\n",
      "\n",
      "Epoch 00002: loss improved from 1.35737 to 1.20946, saving model to ./lstm_model.hdf5\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 80s 6s/step - loss: 1.1438 - acc: 0.4911 - val_loss: 1.1200 - val_acc: 0.5095\n",
      "\n",
      "Epoch 00003: loss improved from 1.20946 to 1.14380, saving model to ./lstm_model.hdf5\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 80s 6s/step - loss: 1.1226 - acc: 0.5204 - val_loss: 1.0906 - val_acc: 0.5475\n",
      "\n",
      "Epoch 00004: loss improved from 1.14380 to 1.12260, saving model to ./lstm_model.hdf5\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 1.0850 - acc: 0.5458 - val_loss: 1.0628 - val_acc: 0.5932\n",
      "\n",
      "Epoch 00005: loss improved from 1.12260 to 1.08504, saving model to ./lstm_model.hdf5\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 89s 7s/step - loss: 1.0675 - acc: 0.5585 - val_loss: 1.0302 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00006: loss improved from 1.08504 to 1.06750, saving model to ./lstm_model.hdf5\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 1.0382 - acc: 0.5763 - val_loss: 1.0101 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00007: loss improved from 1.06750 to 1.03824, saving model to ./lstm_model.hdf5\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 1.0135 - acc: 0.5967 - val_loss: 1.0360 - val_acc: 0.5741\n",
      "\n",
      "Epoch 00008: loss improved from 1.03824 to 1.01354, saving model to ./lstm_model.hdf5\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 83s 6s/step - loss: 1.0106 - acc: 0.6005 - val_loss: 0.9928 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00009: loss improved from 1.01354 to 1.01057, saving model to ./lstm_model.hdf5\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 0.9969 - acc: 0.5878 - val_loss: 0.9980 - val_acc: 0.5894\n",
      "\n",
      "Epoch 00010: loss improved from 1.01057 to 0.99687, saving model to ./lstm_model.hdf5\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 0.9977 - acc: 0.5814 - val_loss: 0.9696 - val_acc: 0.6198\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.99687\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 84s 6s/step - loss: 0.9774 - acc: 0.5980 - val_loss: 0.9589 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00012: loss improved from 0.99687 to 0.97741, saving model to ./lstm_model.hdf5\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 81s 6s/step - loss: 0.9659 - acc: 0.5992 - val_loss: 0.9938 - val_acc: 0.5932\n",
      "\n",
      "Epoch 00013: loss improved from 0.97741 to 0.96588, saving model to ./lstm_model.hdf5\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 78s 6s/step - loss: 0.9648 - acc: 0.5967 - val_loss: 0.9363 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00014: loss improved from 0.96588 to 0.96480, saving model to ./lstm_model.hdf5\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 78s 6s/step - loss: 0.9453 - acc: 0.5814 - val_loss: 0.9593 - val_acc: 0.6046\n",
      "\n",
      "Epoch 00015: loss improved from 0.96480 to 0.94531, saving model to ./lstm_model.hdf5\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.9467 - acc: 0.6094 - val_loss: 0.9357 - val_acc: 0.6236\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.94531\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 75s 6s/step - loss: 0.9318 - acc: 0.6247 - val_loss: 0.9349 - val_acc: 0.6350\n",
      "\n",
      "Epoch 00017: loss improved from 0.94531 to 0.93183, saving model to ./lstm_model.hdf5\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 75s 6s/step - loss: 0.9325 - acc: 0.6056 - val_loss: 0.9467 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.93183\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 75s 6s/step - loss: 0.9219 - acc: 0.6170 - val_loss: 0.9010 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00019: loss improved from 0.93183 to 0.92192, saving model to ./lstm_model.hdf5\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 75s 6s/step - loss: 0.9102 - acc: 0.6285 - val_loss: 0.9092 - val_acc: 0.6350\n",
      "\n",
      "Epoch 00020: loss improved from 0.92192 to 0.91017, saving model to ./lstm_model.hdf5\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 1076s 89s/step - loss: 0.9225 - acc: 0.6069 - val_loss: 0.9055 - val_acc: 0.6426\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.91017\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 2035s 169s/step - loss: 0.9106 - acc: 0.6043 - val_loss: 0.9019 - val_acc: 0.6502\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.91017\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 1009s 84s/step - loss: 0.8931 - acc: 0.6361 - val_loss: 0.8930 - val_acc: 0.6692\n",
      "\n",
      "Epoch 00023: loss improved from 0.91017 to 0.89309, saving model to ./lstm_model.hdf5\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 2005s 167s/step - loss: 0.8901 - acc: 0.6285 - val_loss: 0.8955 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00024: loss improved from 0.89309 to 0.89012, saving model to ./lstm_model.hdf5\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 1992s 166s/step - loss: 0.8755 - acc: 0.6361 - val_loss: 0.8856 - val_acc: 0.6540\n",
      "\n",
      "Epoch 00025: loss improved from 0.89012 to 0.87548, saving model to ./lstm_model.hdf5\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 996s 82s/step - loss: 0.8757 - acc: 0.6234 - val_loss: 0.8809 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.87548\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 2107s 175s/step - loss: 0.8799 - acc: 0.6183 - val_loss: 0.8765 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.87548\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 2122s 176s/step - loss: 0.8653 - acc: 0.6463 - val_loss: 0.8946 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00028: loss improved from 0.87548 to 0.86527, saving model to ./lstm_model.hdf5\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 1110s 92s/step - loss: 0.8556 - acc: 0.6552 - val_loss: 0.8618 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00029: loss improved from 0.86527 to 0.85560, saving model to ./lstm_model.hdf5\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 2105s 175s/step - loss: 0.8458 - acc: 0.6527 - val_loss: 0.8705 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00030: loss improved from 0.85560 to 0.84576, saving model to ./lstm_model.hdf5\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 1948s 162s/step - loss: 0.8548 - acc: 0.6374 - val_loss: 0.8634 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.84576\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 1028s 85s/step - loss: 0.8397 - acc: 0.6527 - val_loss: 0.8733 - val_acc: 0.6578\n",
      "\n",
      "Epoch 00032: loss improved from 0.84576 to 0.83966, saving model to ./lstm_model.hdf5\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 1948s 162s/step - loss: 0.8502 - acc: 0.6514 - val_loss: 0.8838 - val_acc: 0.6654\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.83966\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 1933s 161s/step - loss: 0.8437 - acc: 0.6578 - val_loss: 0.8600 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.83966\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 1135s 94s/step - loss: 0.8437 - acc: 0.6387 - val_loss: 0.8650 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.83966\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 1127s 93s/step - loss: 0.8230 - acc: 0.6667 - val_loss: 0.8705 - val_acc: 0.6692\n",
      "\n",
      "Epoch 00036: loss improved from 0.83966 to 0.82304, saving model to ./lstm_model.hdf5\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.8323 - acc: 0.6514 - val_loss: 0.8782 - val_acc: 0.6426\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.82304\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.8201 - acc: 0.6514 - val_loss: 0.8683 - val_acc: 0.6692\n",
      "\n",
      "Epoch 00038: loss improved from 0.82304 to 0.82014, saving model to ./lstm_model.hdf5\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.8128 - acc: 0.6705 - val_loss: 0.8444 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00039: loss improved from 0.82014 to 0.81282, saving model to ./lstm_model.hdf5\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.8096 - acc: 0.6603 - val_loss: 0.8675 - val_acc: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: loss improved from 0.81282 to 0.80958, saving model to ./lstm_model.hdf5\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.8009 - acc: 0.6768 - val_loss: 0.8437 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00041: loss improved from 0.80958 to 0.80093, saving model to ./lstm_model.hdf5\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.8017 - acc: 0.6628 - val_loss: 0.8577 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.80093\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.7987 - acc: 0.6628 - val_loss: 0.8500 - val_acc: 0.6958\n",
      "\n",
      "Epoch 00043: loss improved from 0.80093 to 0.79870, saving model to ./lstm_model.hdf5\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.7814 - acc: 0.6781 - val_loss: 0.8326 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00044: loss improved from 0.79870 to 0.78135, saving model to ./lstm_model.hdf5\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.7658 - acc: 0.6768 - val_loss: 0.8559 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00045: loss improved from 0.78135 to 0.76581, saving model to ./lstm_model.hdf5\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.7682 - acc: 0.6730 - val_loss: 0.8324 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.76581\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.7690 - acc: 0.6641 - val_loss: 0.8275 - val_acc: 0.6958\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.76581\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 77s 6s/step - loss: 0.7693 - acc: 0.6807 - val_loss: 0.8143 - val_acc: 0.7034\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.76581\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 76s 6s/step - loss: 0.7589 - acc: 0.6921 - val_loss: 0.8201 - val_acc: 0.6958\n",
      "\n",
      "Epoch 00049: loss improved from 0.76581 to 0.75887, saving model to ./lstm_model.hdf5\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 1839s 153s/step - loss: 0.7465 - acc: 0.7010 - val_loss: 0.8388 - val_acc: 0.7072\n",
      "\n",
      "Epoch 00050: loss improved from 0.75887 to 0.74655, saving model to ./lstm_model.hdf5\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "model_file = \"./lstm_model.hdf5\"\n",
    "\n",
    "MAX_PATIENT = 12\n",
    "MAX_EPOCHS = 50\n",
    "MAX_BATCH = 64\n",
    "\n",
    "print(\"training started\")\n",
    "\n",
    "rlrp = ReduceLROnPlateau(patience=MAX_PATIENT, monitor='loss', factor=0.4, verbose=1, min_lr=0.0000001)\n",
    "callback = [rlrp, ModelCheckpoint(filepath=model_file, monitor='loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=MAX_BATCH, epochs=MAX_EPOCHS, verbose=1, validation_data=(x_test, y_test), callbacks=callback)\n",
    "\n",
    "print(\"training finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63ff8c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.89290524],\n",
       "        [ 0.3572929 ],\n",
       "        [ 1.280064  ],\n",
       "        ...,\n",
       "        [ 0.72423744],\n",
       "        [ 0.6890617 ],\n",
       "        [ 1.3716886 ]],\n",
       "\n",
       "       [[-1.8980803 ],\n",
       "        [ 0.8409015 ],\n",
       "        [-0.21610735],\n",
       "        ...,\n",
       "        [-0.37916136],\n",
       "        [ 0.9522005 ],\n",
       "        [-0.5098771 ]],\n",
       "\n",
       "       [[-0.8007864 ],\n",
       "        [ 0.6269899 ],\n",
       "        [ 1.378972  ],\n",
       "        ...,\n",
       "        [ 1.3334322 ],\n",
       "        [ 0.58688676],\n",
       "        [ 1.3473978 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.0099235 ],\n",
       "        [-0.1820338 ],\n",
       "        [-0.17817014],\n",
       "        ...,\n",
       "        [ 0.94541883],\n",
       "        [-1.1512233 ],\n",
       "        [ 0.89792573]],\n",
       "\n",
       "       [[ 0.4543923 ],\n",
       "        [-0.5785093 ],\n",
       "        [-0.02434784],\n",
       "        ...,\n",
       "        [ 0.8425137 ],\n",
       "        [-1.0830256 ],\n",
       "        [-0.19975953]],\n",
       "\n",
       "       [[ 1.4269778 ],\n",
       "        [-0.537312  ],\n",
       "        [-1.490688  ],\n",
       "        ...,\n",
       "        [ 1.2167845 ],\n",
       "        [-0.29672724],\n",
       "        [ 0.4474781 ]]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08e859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
