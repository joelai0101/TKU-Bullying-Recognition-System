{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58128279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import wave\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3739fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "original_root = './original'\n",
    "\n",
    "path_list = []\n",
    "\n",
    "for path, subdirs, files in os.walk(original_root):\n",
    "    for name in files:\n",
    "        if name.endswith(\".wav\"):\n",
    "            # print(os.path.join(path, name))\n",
    "            path_list.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f645565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b561c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_root = original_root+'/生氣-大聲'\n",
    "calm_root =  original_root+'/溫柔-平靜'\n",
    "taunt_root = original_root+'/威脅-挑釁-惹對方生氣'\n",
    "upset_root = original_root+'/求饒-難過'\n",
    "\n",
    "angry_padding_root = './padding/angry'\n",
    "calm_padding_root =  './padding/calm'\n",
    "taunt_padding_root = './padding/taunt'\n",
    "upset_padding_root = './padding/upset'\n",
    "\n",
    "angry_augmentation_root = './augmented/angry'\n",
    "calm_augmentation_root =  './augmented/calm'\n",
    "taunt_augmentation_root = './augmented/taunt'\n",
    "upset_augmentation_root = './augmented/upset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c65886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_path_list(root):\n",
    "    path_list = []\n",
    "\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if name.endswith(\".wav\"):\n",
    "                # print(os.path.join(path, name))\n",
    "                path_list.append(os.path.join(path, name))\n",
    "    return path_list\n",
    "\n",
    "def remove_duration_too_Long_path(path_list):\n",
    "    durations = [librosa.get_duration(filename=p) for p in path_list]\n",
    "    tooLong = [idx for idx, ele in enumerate(durations) if ele > 10.0]\n",
    "    tooLong_path = [path_list[i] for i in tooLong]\n",
    "    new_path_list = list(set(path_list) - set(tooLong_path))\n",
    "    return new_path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fa050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "347\n",
      "491\n",
      "490\n",
      "120\n",
      "119\n",
      "164\n",
      "99\n",
      "1055\n"
     ]
    }
   ],
   "source": [
    "angry_path_list = get_wav_path_list(angry_root)\n",
    "print(len(angry_path_list))\n",
    "angry_path_list = remove_duration_too_Long_path(angry_path_list)\n",
    "print(len(angry_path_list))\n",
    "\n",
    "calm_path_list = get_wav_path_list(calm_root)\n",
    "print(len(calm_path_list))\n",
    "calm_path_list = remove_duration_too_Long_path(calm_path_list)\n",
    "print(len(calm_path_list))\n",
    "\n",
    "taunt_path_list = get_wav_path_list(taunt_root)\n",
    "print(len(taunt_path_list))\n",
    "taunt_path_list = remove_duration_too_Long_path(taunt_path_list)\n",
    "print(len(taunt_path_list))\n",
    "\n",
    "upset_path_list = get_wav_path_list(upset_root)\n",
    "print(len(upset_path_list))\n",
    "upset_path_list = remove_duration_too_Long_path(upset_path_list)\n",
    "print(len(upset_path_list))\n",
    "\n",
    "print(len(angry_path_list)+len(calm_path_list)+len(taunt_path_list)+len(upset_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de5b2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_padding(padding_root, path_list):\n",
    "    for path in path_list:\n",
    "\n",
    "        f = wave.open(path)\n",
    "        SampleRate = f.getframerate()\n",
    "        frames = f.getnframes()\n",
    "        Duration = wav_time = frames / float(SampleRate)\n",
    "        wav, sr = librosa.load(path, sr=16000)\n",
    "        if Duration <= 10.0:\n",
    "            n = 160000-wav.shape[0]\n",
    "            ndarray = np.pad(wav, (0, n), 'constant', constant_values=(0,0.0000000e+00))\n",
    "            sf.write(os.path.join(padding_root, 'padding_'+os.path.basename(path)), ndarray, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dc866",
   "metadata": {},
   "source": [
    "## Data Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef4a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padding(angry_padding_root, angry_path_list)\n",
    "data_padding(calm_padding_root, calm_path_list)\n",
    "data_padding(taunt_padding_root, taunt_path_list)\n",
    "data_padding(upset_padding_root, upset_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72946fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "{'mean': 10.0, 'max': 10.0, 'min': 10.0}\n"
     ]
    }
   ],
   "source": [
    "angry_padding_path_list = get_wav_path_list(angry_padding_root)\n",
    "print(len(angry_padding_path_list))\n",
    "angry_padding_durations = [librosa.get_duration(filename=p) for p in angry_padding_path_list]\n",
    "\n",
    "angry_padding_stats = {\n",
    "    'mean': np.mean(angry_padding_durations),\n",
    "    'max': np.max(angry_padding_durations),\n",
    "    'min': np.min(angry_padding_durations),\n",
    "}\n",
    "\n",
    "print(angry_padding_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d1ab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_Injection(data, noise_factor):\n",
    "    # Adding white noise \n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    # Cast back to same data type\n",
    "    augmented_data = augmented_data.astype(type(data[0]))\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30fafd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shifting_Time(data, shift=16000):\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fdd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangingPitch(data, sampling_rate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def ChangingSpeed(data, speed_factor):\n",
    "    \n",
    "    input_length = 160000\n",
    "    data = librosa.effects.time_stretch(data, speed_factor)\n",
    "    if len(data)>input_length:\n",
    "        data = data[:input_length]\n",
    "    else:\n",
    "        data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e884e62d",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ac375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(augmentation_root, path_list):\n",
    "    \n",
    "    for path in path_list:\n",
    "        data, _ = librosa.load(path, sr=16000)\n",
    "        \n",
    "        data_noise = Noise_Injection(data, 0.005)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_noise005_'+os.path.basename(path)), data_noise, 16000)\n",
    "        data_noise = Noise_Injection(data, 0.01)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_noise01_'+os.path.basename(path)), data_noise, 16000)\n",
    "        data_noise = Noise_Injection(data, 0.05)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_noise05_'+os.path.basename(path)), data_noise, 16000)\n",
    "        \n",
    "        data_shift = Shifting_Time(data, 16000)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_shift16_'+os.path.basename(path)), data_shift, 16000)\n",
    "        data_shift = Shifting_Time(data, 32000)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_shift32_'+os.path.basename(path)), data_shift, 16000)\n",
    "        data_shift = Shifting_Time(data, 48000)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_shift48_'+os.path.basename(path)), data_shift, 16000)\n",
    "        \n",
    "        \n",
    "        data_pitch = ChangingPitch(data, sampling_rate=16000, pitch_factor=0.8)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_pitch08_'+os.path.basename(path)), data_pitch, 16000)\n",
    "        data_pitch = ChangingPitch(data, sampling_rate=16000, pitch_factor=0.9)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_pitch09_'+os.path.basename(path)), data_pitch, 16000)\n",
    "        data_pitch = ChangingPitch(data, sampling_rate=16000, pitch_factor=1.1)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_pitch11_'+os.path.basename(path)), data_pitch, 16000)\n",
    "        data_pitch = ChangingPitch(data, sampling_rate=16000, pitch_factor=1.2)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_pitch12_'+os.path.basename(path)), data_pitch, 16000)\n",
    "        \n",
    "        data_speed = ChangingSpeed(data, speed_factor=0.8)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_speed08_'+os.path.basename(path)), data_speed, 16000)\n",
    "        data_speed = ChangingSpeed(data, speed_factor=0.9)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_speed09_'+os.path.basename(path)), data_speed, 16000)\n",
    "        data_speed = ChangingSpeed(data, speed_factor=1.1)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_speed11_'+os.path.basename(path)), data_speed, 16000)\n",
    "        data_speed = ChangingSpeed(data, speed_factor=1.2)\n",
    "        sf.write(os.path.join(augmentation_root, 'data_speed12_'+os.path.basename(path)), data_speed, 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e2908bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:2: FutureWarning: Pass sr=16000, n_steps=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:2: FutureWarning: Pass sr=16000, n_steps=0.9 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:2: FutureWarning: Pass sr=16000, n_steps=1.1 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:2: FutureWarning: Pass sr=16000, n_steps=1.2 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:7: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  data = librosa.effects.time_stretch(data, speed_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:7: FutureWarning: Pass rate=0.9 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  data = librosa.effects.time_stretch(data, speed_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:7: FutureWarning: Pass rate=1.1 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  data = librosa.effects.time_stretch(data, speed_factor)\n",
      "/var/folders/rd/yxk_41h92vz6r66k9g09_fjw0000gn/T/ipykernel_3013/1876425822.py:7: FutureWarning: Pass rate=1.2 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  data = librosa.effects.time_stretch(data, speed_factor)\n"
     ]
    }
   ],
   "source": [
    "angry_padding_path_list = get_wav_path_list(angry_padding_root)\n",
    "data_augmentation(angry_augmentation_root, angry_padding_path_list)\n",
    "calm_padding_path_list = get_wav_path_list(calm_padding_root)\n",
    "data_augmentation(calm_augmentation_root, calm_padding_path_list)\n",
    "taunt_padding_path_list = get_wav_path_list(taunt_padding_root)\n",
    "data_augmentation(taunt_augmentation_root, taunt_padding_path_list)\n",
    "upset_padding_path_list = get_wav_path_list(upset_padding_root)\n",
    "data_augmentation(upset_augmentation_root, upset_padding_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f090a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4816\n",
      "{'mean': 10.0, 'max': 10.0, 'min': 10.0}\n",
      "6846\n",
      "{'mean': 10.0, 'max': 10.0, 'min': 10.0}\n",
      "1652\n",
      "{'mean': 10.0, 'max': 10.0, 'min': 10.0}\n",
      "1372\n",
      "{'mean': 10.0, 'max': 10.0, 'min': 10.0}\n"
     ]
    }
   ],
   "source": [
    "angry_augmentation_path_list = get_wav_path_list(angry_augmentation_root)\n",
    "\n",
    "print(len(angry_augmentation_path_list))\n",
    "angry_augmentation_durations = [librosa.get_duration(filename=p) for p in angry_augmentation_path_list]\n",
    "\n",
    "angry_augmentation_stats = {\n",
    "    'mean': np.mean(angry_augmentation_durations),\n",
    "    'max': np.max(angry_augmentation_durations),\n",
    "    'min': np.min(angry_augmentation_durations),\n",
    "}\n",
    "\n",
    "print(angry_augmentation_stats)\n",
    "\n",
    "calm_augmentation_path_list = get_wav_path_list(calm_augmentation_root)\n",
    "\n",
    "print(len(calm_augmentation_path_list))\n",
    "calm_augmentation_durations = [librosa.get_duration(filename=p) for p in calm_augmentation_path_list]\n",
    "\n",
    "calm_augmentation_stats = {\n",
    "    'mean': np.mean(calm_augmentation_durations),\n",
    "    'max': np.max(calm_augmentation_durations),\n",
    "    'min': np.min(calm_augmentation_durations),\n",
    "}\n",
    "\n",
    "print(calm_augmentation_stats)\n",
    "\n",
    "taunt_augmentation_path_list = get_wav_path_list(taunt_augmentation_root)\n",
    "\n",
    "print(len(taunt_augmentation_path_list))\n",
    "taunt_augmentation_durations = [librosa.get_duration(filename=p) for p in taunt_augmentation_path_list]\n",
    "\n",
    "taunt_augmentation_stats = {\n",
    "    'mean': np.mean(taunt_augmentation_durations),\n",
    "    'max': np.max(taunt_augmentation_durations),\n",
    "    'min': np.min(taunt_augmentation_durations),\n",
    "}\n",
    "\n",
    "print(taunt_augmentation_stats)\n",
    "\n",
    "upset_augmentation_path_list = get_wav_path_list(upset_augmentation_root)\n",
    "\n",
    "print(len(upset_augmentation_path_list))\n",
    "upset_augmentation_durations = [librosa.get_duration(filename=p) for p in upset_augmentation_path_list]\n",
    "\n",
    "upset_augmentation_stats = {\n",
    "    'mean': np.mean(upset_augmentation_durations),\n",
    "    'max': np.max(upset_augmentation_durations),\n",
    "    'min': np.min(upset_augmentation_durations),\n",
    "}\n",
    "\n",
    "print(upset_augmentation_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764729c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
